import logging
import logging.config
from config import LOG_CONFIG
from database import Database
# æµ‹è¯•
from crawler import RaceCrawler
from image_analyzer import ImageAnalyzer
from data_extractor import DataExtractor
from data_completer_enhanced import EnhancedDataCompleter
from enhanced_html_extractor import EnhancedHtmlCategoryExtractor

import time
import sys
import os
import concurrent.futures
from data_processor import EnhancedDataProcessor

os.system('chcp 65001')  # Windows æ§åˆ¶å°åˆ‡æ¢ UTF-8 ç¼–ç 

# é…ç½®æ—¥å¿—ï¼Œå…ˆç”¨ dictConfig è¿›è¡Œé…ç½®
logging.config.dictConfig(LOG_CONFIG)
logger = logging.getLogger()


# è‡ªå®šä¹‰å®‰å…¨ç¼–ç æ—¥å¿—å¤„ç†å™¨ï¼Œå®šä¹‰ä¸€æ¬¡å³å¯
class SafeEncodingHandler(logging.StreamHandler):
    """å®‰å…¨ç¼–ç çš„æ—¥å¿—å¤„ç†å™¨ï¼Œé¿å…UnicodeEncodeError"""

    def emit(self, record):
        try:
            msg = self.format(record)
            stream = self.stream
            stream.write(msg + self.terminator)
            self.flush()
        except UnicodeEncodeError:
            # å‘ç”Ÿç¼–ç é”™è¯¯æ—¶ï¼Œå¿½ç•¥æ— æ³•ç¼–ç çš„å­—ç¬¦
            safe_msg = msg.encode(stream.encoding, errors='ignore').decode(stream.encoding)
            stream.write(safe_msg + self.terminator)
            self.flush()


# æ¸…é™¤é»˜è®¤çš„ handlerï¼Œæ·»åŠ è‡ªå®šä¹‰ handler
logger.handlers.clear()
handler = SafeEncodingHandler(sys.stdout)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)


class RaceCrawlerApp:
    """èµ›äº‹çˆ¬è™«åº”ç”¨"""

    def __init__(self):
        self.db = Database()
        self.crawler = RaceCrawler()
        self.image_analyzer = ImageAnalyzer()
        self.data_extractor = DataExtractor()
        self.data_completer = EnhancedDataCompleter()
        self.html_extractor = EnhancedHtmlCategoryExtractor()

        # â­ æ–°å¢ï¼šæ™ºèƒ½åŒæ­¥å™¨
        from race_events_manager import DB_CONFIG

    def init(self):
        """åˆå§‹åŒ–"""
        logger.info("åˆå§‹åŒ–æ•°æ®åº“...")
        self.db.init_db()
        logger.info("åˆå§‹åŒ–å®Œæˆ\n")

    def _convert_to_mysql_format(self, sqlite_data: dict) -> list:
        """
        å°†SQLiteæ•°æ®æ ¼å¼è½¬æ¢ä¸ºMySQLæ ¼å¼

        Args:
            sqlite_data: SQLiteæ ¼å¼çš„æ•°æ®ï¼ˆä¸€ä¸ªèµ›äº‹åŒ…å«å¤šä¸ªç»„åˆ«ï¼‰

        Returns:
            list: MySQLæ ¼å¼çš„æ•°æ®ï¼ˆæ¯ä¸ªç»„åˆ«ä¸€æ¡è®°å½•ï¼‰
        """
        mysql_records = []

        # åŸºæœ¬ä¿¡æ¯
        event_id = sqlite_data.get('event_id')
        event_url = sqlite_data.get('event_url')
        event_name = sqlite_data.get('name')
        event_date = sqlite_data.get('event_date')
        event_level = sqlite_data.get('event_level')
        location = sqlite_data.get('location')
        detailed_address = sqlite_data.get('detailed_address')
        status = sqlite_data.get('status')
        total_scale = sqlite_data.get('total_scale')
        registration_fee = sqlite_data.get('registration_fee')
        organizer = sqlite_data.get('organizer')
        host_units = sqlite_data.get('host_units')
        co_organizers = sqlite_data.get('co_organizers')
        supporters = sqlite_data.get('supporters')
        contact_phone = sqlite_data.get('contact_phone')
        contact_email = sqlite_data.get('contact_email')
        contact_person = sqlite_data.get('contact_person')
        registration_deadline = sqlite_data.get('registration_deadline')

        # ç»„åˆ«ä¿¡æ¯
        categories = sqlite_data.get('race_categories', [])

        if not categories:
            # å¦‚æœæ²¡æœ‰ç»„åˆ«ï¼Œåˆ›å»ºä¸€æ¡ç©ºè®°å½•
            mysql_records.append({
                'event_id': event_id,
                'event_url': event_url,
                'event_name': event_name,
                'event_date': event_date,
                'event_level': event_level,
                'location': location,
                'detailed_address': detailed_address,
                'status': status,
                'total_scale': total_scale,
                'registration_fee': registration_fee,
                'organizer': organizer,
                'host_units': host_units,
                'co_organizers': co_organizers,
                'supporters': supporters,
                'contact_phone': contact_phone,
                'contact_email': contact_email,
                'contact_person': contact_person,
                'registration_deadline': registration_deadline,
                'name': None,  # ç»„åˆ«åç§°
                'distance_numeric': None,
                'fee': None,
                'price_per_km': None,
                'zaoniao_fee': None,
                'total_quota': None,
                'start_time': None,
                'cutoff_time': None
            })
        else:
            # æ¯ä¸ªç»„åˆ«åˆ›å»ºä¸€æ¡è®°å½•
            for cat in categories:
                mysql_records.append({
                    'event_id': event_id,
                    'event_url': event_url,
                    'event_name': event_name,
                    'event_date': event_date,
                    'event_level': event_level,
                    'location': location,
                    'detailed_address': detailed_address,
                    'status': status,
                    'total_scale': total_scale,
                    'registration_fee': registration_fee,
                    'organizer': organizer,
                    'host_units': host_units,
                    'co_organizers': co_organizers,
                    'supporters': supporters,
                    'contact_phone': contact_phone,
                    'contact_email': contact_email,
                    'contact_person': contact_person,
                    'registration_deadline': registration_deadline,
                    'name': cat.get('name'),
                    'distance_numeric': cat.get('distance_numeric'),
                    'fee': cat.get('fee'),
                    'price_per_km': cat.get('price_per_km'),
                    'zaoniao_fee': cat.get('zaoniao_fee'),
                    'total_quota': cat.get('total_quota'),
                    'start_time': cat.get('start_time'),
                    'cutoff_time': cat.get('cutoff_time')
                })

        return mysql_records

    def _sync_to_mysql(self, manager, mysql_records: list) -> bool:
        """
        åŒæ­¥æ•°æ®åˆ°MySQL

        Args:
            manager: RaceEventsManagerå®ä¾‹
            mysql_records: MySQLæ ¼å¼çš„è®°å½•åˆ—è¡¨

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            import pymysql
            from datetime import datetime

            conn = manager._get_connection()
            cursor = conn.cursor()

            for record in mysql_records:
                event_id = record['event_id']
                name = record.get('name')

                # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨
                if name:
                    cursor.execute(
                        "SELECT id FROM race_categories WHERE event_id=%s AND name=%s",
                        (event_id, name)
                    )
                else:
                    cursor.execute(
                        "SELECT id FROM race_categories WHERE event_id=%s AND (name IS NULL OR name='')",
                        (event_id,)
                    )

                existing = cursor.fetchone()

                if existing:
                    # æ›´æ–°
                    cursor.execute("""
                        UPDATE race_categories SET
                            event_url=%s, event_name=%s, event_date=%s, event_level=%s,
                            location=%s, detailed_address=%s, status=%s, total_scale=%s,
                            registration_fee=%s, organizer=%s, host_units=%s, co_organizers=%s,
                            supporters=%s, contact_phone=%s, contact_email=%s, contact_person=%s,
                            registration_deadline=%s, distance_numeric=%s, fee=%s, price_per_km=%s,
                            zaoniao_fee=%s, total_quota=%s, start_time=%s, cutoff_time=%s,
                            updated_at=%s
                        WHERE id=%s
                    """, (
                        record.get('event_url'), record.get('event_name'), record.get('event_date'),
                        record.get('event_level'), record.get('location'), record.get('detailed_address'),
                        record.get('status'), record.get('total_scale'), record.get('registration_fee'),
                        record.get('organizer'), record.get('host_units'), record.get('co_organizers'),
                        record.get('supporters'), record.get('contact_phone'), record.get('contact_email'),
                        record.get('contact_person'), record.get('registration_deadline'),
                        record.get('distance_numeric'), record.get('fee'), record.get('price_per_km'),
                        record.get('zaoniao_fee'), record.get('total_quota'), record.get('start_time'),
                        record.get('cutoff_time'), datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        existing[0]
                    ))
                else:
                    # æ’å…¥
                    cursor.execute("""
                        INSERT INTO race_categories (
                            event_id, event_url, event_name, event_date, event_level,
                            location, detailed_address, status, total_scale, registration_fee,
                            organizer, host_units, co_organizers, supporters,
                            contact_phone, contact_email, contact_person, registration_deadline,
                            name, distance_numeric, fee, price_per_km, zaoniao_fee,
                            total_quota, start_time, cutoff_time,
                            created_at, updated_at
                        ) VALUES (
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                            %s, %s, %s, %s, %s, %s, %s, %s
                        )
                    """, (
                        record.get('event_id'), record.get('event_url'), record.get('event_name'),
                        record.get('event_date'), record.get('event_level'), record.get('location'),
                        record.get('detailed_address'), record.get('status'), record.get('total_scale'),
                        record.get('registration_fee'), record.get('organizer'), record.get('host_units'),
                        record.get('co_organizers'), record.get('supporters'), record.get('contact_phone'),
                        record.get('contact_email'), record.get('contact_person'), record.get('registration_deadline'),
                        record.get('name'), record.get('distance_numeric'), record.get('fee'),
                        record.get('price_per_km'), record.get('zaoniao_fee'), record.get('total_quota'),
                        record.get('start_time'), record.get('cutoff_time'),
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    ))

            conn.commit()
            conn.close()
            return True

        except Exception as e:
            logger.error(f"MySQLåŒæ­¥é”™è¯¯: {e}")
            return False

    def process_event(self, event: dict):
        """å¤„ç†å•ä¸ªèµ›äº‹"""
        try:
            logger.info(f"\n" + "=" * 80)
            logger.info(f"å¤„ç†èµ›äº‹: {event['name']}")
            logger.info(f"èµ›äº‹ID: {event['event_id']}")
            logger.info(f"è¯¦æƒ…URL: {event['event_url']}")
            logger.info("=" * 80)

            # æ­¥éª¤1: çˆ¬å–è¯¦æƒ…å’Œèµ„è®¯
            logger.info("\nã€æ­¥éª¤1/5ã€‘çˆ¬å–èµ›äº‹è¯¦æƒ…å’Œèµ„è®¯å†…å®¹")
            logger.info("-" * 80)

            event_detail = self.crawler.crawl_event_detail(event)

            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            if not event_detail.get('news_url'):
                logger.warning(f"âš  æœªæ‰¾åˆ°èµ„è®¯URL")
            else:
                logger.info(f"âœ“ èµ„è®¯URL: {event_detail['news_url']}")

            if not event_detail.get('news_content_raw'):
                logger.warning(f"âš  æœªè·å–åˆ°èµ„è®¯å†…å®¹")
            else:
                logger.info(f"âœ“ èµ„è®¯æ–‡æœ¬: {len(event_detail['news_content_raw'])} å­—ç¬¦")

            if not event_detail.get('detail_text'):
                logger.warning(f"âš  æœªè·å–åˆ°è¯¦æƒ…é¡µæ–‡æœ¬")
            else:
                logger.info(f"âœ“ è¯¦æƒ…æ–‡æœ¬: {len(event_detail['detail_text'])} å­—ç¬¦")

            # æ­¥éª¤2: åˆ†æå›¾ç‰‡
            logger.info(f"\nã€æ­¥éª¤2/5ã€‘åˆ†æèµ„è®¯å›¾ç‰‡")
            logger.info("-" * 80)

            images_analysis = []
            if event_detail.get('images') and len(event_detail['images']) > 0:
                logger.info(f"å‡†å¤‡åˆ†æ {len(event_detail['images'])} å¼ å›¾ç‰‡ï¼ˆæœ€å¤šåˆ†æ10å¼ ï¼‰")
                images_to_analyze = event_detail['images'][:10]

                try:
                    images_analysis = self.image_analyzer.analyze_images_batch(images_to_analyze)
                    logger.info(f"âœ“ æˆåŠŸåˆ†æ {len(images_analysis)} å¼ å›¾ç‰‡")
                except Exception as e:
                    logger.error(f"âœ— å›¾ç‰‡åˆ†æå¤±è´¥: {e}")

                event_detail['images_analysis'] = images_analysis
            else:
                logger.info("è·³è¿‡ï¼ˆæ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼‰")
                event_detail['images_analysis'] = []

            # æ­¥éª¤3: æå–ç»“æ„åŒ–æ•°æ®
            logger.info(f"\nã€æ­¥éª¤3/6ã€‘ä½¿ç”¨AIæ¨¡å‹æå–ç»“æ„åŒ–æ•°æ®")
            logger.info("-" * 80)

            structured_data = {}
            try:
                structured_data = self.data_extractor.extract_structured_data(event_detail)
                if structured_data:
                    logger.info(f"âœ“ æˆåŠŸæå–ç»“æ„åŒ–æ•°æ®:")
                    logger.info(f"  Â· èµ›äº‹åç§°: {structured_data.get('name', 'null')}")
                    logger.info(f"  Â· èµ›äº‹æ—¥æœŸ: {structured_data.get('event_date', 'null')}")
                    logger.info(f"  Â· èµ›äº‹ç­‰çº§: {structured_data.get('event_level', 'null')}")
                    logger.info(f"  Â· æ¯”èµ›åœ°ç‚¹: {structured_data.get('location', 'null')}")
                    logger.info(f"  Â· è¯¦ç»†åœ°å€: {structured_data.get('detailed_address', 'null')}")
                    logger.info(f"  Â· ç»„åˆ«æ•°é‡: {len(structured_data.get('race_categories', []))}")
                    logger.info(f"  Â· èµ›äº‹æ€»è§„æ¨¡: {structured_data.get('total_scale', 'null')}")
                    logger.info(f"  Â· æŠ¥åè´¹ç”¨: {structured_data.get('registration_fee', 'null')}")
                    logger.info(f"  Â· è¿è¥å•ä½: {structured_data.get('organizer', 'null')}")
                    logger.info(f"  Â· ä¸»åŠå•ä½: {structured_data.get('host_units', 'null')}")
                    logger.info(f"  Â· æ‰¿åŠå•ä½: {structured_data.get('co_organizers', 'null')}")
                    logger.info(f"  Â· è”ç³»ç”µè¯: {structured_data.get('contact_phone', 'null')}")
                    logger.info(f"  Â· è”ç³»é‚®ç®±: {structured_data.get('contact_email', 'null')}")

                    # æ˜¾ç¤ºç»„åˆ«è¯¦æƒ…
                    if structured_data.get('race_categories'):
                        logger.info(f"  Â· ç»„åˆ«è¯¦æƒ…:")
                        for idx, cat in enumerate(structured_data['race_categories'], 1):
                            logger.info(f"    {idx}. {cat.get('name', 'unknown')} - "
                                        f"{cat.get('distance', 'unknown')} - "
                                        f"è´¹ç”¨: {cat.get('fee', 'unknown')} - "
                                        f"å·²æŠ¥: {cat.get('registered_count', 'unknown')}")
                else:
                    logger.warning("âš  AIæ¨¡å‹è¿”å›äº†ç©ºæ•°æ®")
            except Exception as e:
                logger.error(f"âœ— æå–ç»“æ„åŒ–æ•°æ®å¤±è´¥: {e}")

            # æ­¥éª¤4: æ™ºèƒ½è¡¥å…¨ç¼ºå¤±æ•°æ®
            logger.info(f"\nã€æ­¥éª¤4/6ã€‘æ™ºèƒ½è¡¥å…¨ç¼ºå¤±æ•°æ®")
            logger.info("-" * 80)

            if structured_data:
                try:
                    event_name = structured_data.get('name') or event.get('name')
                    completed_data = self.data_completer.complete_event_data(event_name, structured_data)

                    # ä½¿ç”¨è¡¥å…¨åçš„æ•°æ®
                    structured_data = completed_data

                    # æ˜¾ç¤ºè¡¥å…¨åçš„ç»„åˆ«è¯¦æƒ…
                    if structured_data.get('race_categories'):
                        logger.info(f"\nè¡¥å…¨åçš„ç»„åˆ«è¯¦æƒ…:")
                        logger.info(f"  èµ›äº‹æ€»è§„æ¨¡: {structured_data.get('total_scale', 'unknown')}")
                        for idx, cat in enumerate(structured_data['race_categories'], 1):
                            logger.info(f"  {idx}. {cat.get('name', 'unknown')} - "
                                        f"{cat.get('distance', 'unknown')} - "
                                        f"è´¹ç”¨: {cat.get('fee', 'unknown')} - "
                                        f"åé¢: {cat.get('total_quota', 'unknown')}")
                except Exception as e:
                    logger.error(f"âœ— æ•°æ®è¡¥å…¨å¤±è´¥: {e}")
                    logger.warning("âš  å°†ä½¿ç”¨åŸå§‹æå–çš„æ•°æ®")
            else:
                logger.info("è·³è¿‡ï¼ˆæ²¡æœ‰æå–åˆ°ç»“æ„åŒ–æ•°æ®ï¼‰")

            # æ­¥éª¤5: åˆå¹¶æ•°æ®
            logger.info(f"\nã€æ­¥éª¤5/6ã€‘åˆå¹¶æ•°æ®")
            logger.info("-" * 80)

            # æå–èµ›äº‹è¯¦æƒ…
            detail_html = event_detail.get('raw_html')
            event_detail_text = None
            if detail_html:
                try:
                    event_detail_text = self.html_extractor.extract_event_detail(detail_html)
                    if event_detail_text:
                        logger.info(f"âœ“ èµ›äº‹è¯¦æƒ…æå–æˆåŠŸ: {len(event_detail_text)} å­—ç¬¦")
                    else:
                        logger.info("âš ï¸  æœªæå–åˆ°èµ›äº‹è¯¦æƒ…")
                except Exception as e:
                    logger.error(f"âœ— èµ›äº‹è¯¦æƒ…æå–å¤±è´¥: {e}")
            else:
                logger.info("âš ï¸  æ— è¯¦æƒ…é¡µHTMLï¼Œè·³è¿‡è¯¦æƒ…æå–")

            # ========================================
            # âœ¨âœ¨âœ¨ æ–°å¢ï¼šåˆå¹¶crawlerå’ŒAIçš„ç»„åˆ«æ•°æ® âœ¨âœ¨âœ¨
            # ========================================
            logger.info(f"\nã€æ•°æ®åˆå¹¶ã€‘åˆå¹¶crawlerå’ŒAIæå–çš„ç»„åˆ«æ•°æ®")
            logger.info("-" * 80)

            # è·å–ä¸¤è¾¹çš„æ•°æ®
            crawler_categories = event_detail.get('categories', [])
            ai_categories = structured_data.get('race_categories', [])

            merged_categories = []

            if crawler_categories:
                logger.info(f"âœ“ crawleræå–äº† {len(crawler_categories)} ä¸ªç»„åˆ«ï¼ˆåŒ…å«æŠ¥åçŠ¶æ€ï¼‰")

                # éå†crawlerçš„æ¯ä¸ªç»„åˆ«
                for crawler_cat in crawler_categories:
                    cat_name = crawler_cat.get('name', '')

                    # åœ¨AIæ•°æ®ä¸­æŸ¥æ‰¾å¯¹åº”çš„ç»„åˆ«
                    ai_cat = None
                    for ac in ai_categories:
                        if ac.get('name') == cat_name:
                            ai_cat = ac
                            break

                    if ai_cat is None:
                        ai_cat = {}

                    # åˆå¹¶æ•°æ®ï¼šAIçš„è¯¦ç»†ä¿¡æ¯ + crawlerçš„æŠ¥åçŠ¶æ€
                    merged_cat = {
                        'name': crawler_cat.get('name'),
                        'distance': ai_cat.get('distance') or crawler_cat.get('distance'),
                        'fee': ai_cat.get('fee') or crawler_cat.get('fee'),
                        'zaoniao_fee': ai_cat.get('zaoniao_fee'),
                        'total_quota': ai_cat.get('total_quota'),
                        'registered_count': ai_cat.get('registered_count'),
                        'start_time': ai_cat.get('start_time'),
                        'cutoff_time': ai_cat.get('cutoff_time'),

                        # âœ¨ å…³é”®ï¼šä¿ç•™crawleræå–çš„æŠ¥åçŠ¶æ€å­—æ®µ
                        'registration_status': crawler_cat.get('registration_status'),
                        'registration_url': crawler_cat.get('registration_url')
                    }

                    merged_categories.append(merged_cat)

                    # è¾“å‡ºæ—¥å¿—
                    status_str = merged_cat['registration_status'] or 'NULL'
                    url_preview = merged_cat['registration_url'][:35] + '...' if merged_cat[
                        'registration_url'] else 'NULL'
                    logger.info(f"  Â· {cat_name}: çŠ¶æ€={status_str}, é“¾æ¥={url_preview}")

                logger.info(f"âœ“ åˆå¹¶å®Œæˆï¼Œä¿ç•™äº† {len(merged_categories)} ä¸ªç»„åˆ«çš„æŠ¥åçŠ¶æ€å’Œé“¾æ¥")

            else:
                # å¦‚æœcrawleræ²¡æå–åˆ°ï¼Œç”¨AIçš„
                logger.warning(f"âš ï¸  crawleræœªæå–åˆ°ç»„åˆ«ï¼Œä½¿ç”¨AIæ•°æ®ï¼ˆå¯èƒ½ç¼ºå°‘æŠ¥åçŠ¶æ€ï¼‰")
                merged_categories = ai_categories

            # ä¼˜å…ˆä½¿ç”¨crawlerçš„èµ›äº‹æ•´ä½“çŠ¶æ€
            event_status = event_detail.get('status') or structured_data.get('status', 'active')
            status_source = 'crawler(HTML)' if event_detail.get('status') else 'AI'
            logger.info(f"âœ“ èµ›äº‹æ•´ä½“çŠ¶æ€: {event_status} (æ¥æº: {status_source})")
            logger.info("-" * 80)
            # ========================================
            # âœ¨âœ¨âœ¨ åˆå¹¶ç»“æŸ âœ¨âœ¨âœ¨
            # ========================================

            final_data = {
                'event_id': event['event_id'],
                'event_url': event['event_url'],
                'name': structured_data.get('name') or event.get('name'),
                'event_date': structured_data.get('event_date'),
                'event_level': structured_data.get('event_level'),
                'location': structured_data.get('location'),
                'detailed_address': structured_data.get('detailed_address'),
                'race_categories': merged_categories ,
                'total_scale': structured_data.get('total_scale'),
                'registration_fee': structured_data.get('registration_fee'),
                'organizer': structured_data.get('organizer'),
                'host_units': structured_data.get('host_units'),
                'co_organizers': structured_data.get('co_organizers'),
                'supporters': structured_data.get('supporters'),
                'contact_phone': structured_data.get('contact_phone'),
                'contact_email': structured_data.get('contact_email'),
                'contact_person': structured_data.get('contact_person'),
                'registration_deadline': structured_data.get('registration_deadline') or event.get(
                    'registration_deadline'),
                'status': event_status , # ä¼˜å…ˆä½¿ç”¨crawlerçš„status
                'description': event_detail.get('detail_text', ''),
                'news_content': event_detail.get('news_content_raw'),
                'images_analysis': event_detail.get('images_analysis'),
                'news_url': event_detail.get('news_url'),
                'event_detail': event_detail_text,
                'raw_html': event_detail.get('raw_html')
            }

            logger.info(f"âœ“ æ•°æ®åˆå¹¶å®Œæˆ")

            # æ­¥éª¤6: ä¿å­˜åˆ°æ•°æ®åº“
            logger.info(f"\nã€æ­¥éª¤6/6ã€‘ä¿å­˜åˆ°æ•°æ®åº“")
            logger.info("-" * 80)
            final_data = EnhancedDataProcessor.process_event_data(final_data)
            # âœ¨ ä½¿ç”¨æ™ºèƒ½åŒæ­¥ï¼Œä¿æŠ¤äººå·¥ä¿®æ”¹
            try:
                from smart_crawler_sync import SmartCrawlerSync
                from config import DATABASE_CONFIG

                smart_sync = SmartCrawlerSync(DATABASE_CONFIG)
                success = smart_sync.smart_sync_to_mysql(final_data)

                if success:
                    logger.debug(f"  âœ“ æ™ºèƒ½åŒæ­¥: {final_data}")
            except ImportError as e:
                logger.warning(f"  âš ï¸  SmartCrawlerSyncä¸å¯ç”¨: {e}ï¼Œä½¿ç”¨æ™®é€šä¿å­˜")
                success = self.db.save_race_event(final_data)
            except Exception as e:
                logger.warning(f"  âš ï¸  æ™ºèƒ½åŒæ­¥å¤±è´¥: {e}ï¼Œä½¿ç”¨æ™®é€šä¿å­˜")
                success = self.db.save_race_event(final_data)
            if success:
                logger.info(f"âœ“âœ“âœ“ æˆåŠŸä¿å­˜èµ›äº‹åˆ°MySQLæ•°æ®åº“")

                # éªŒè¯ä¿å­˜
                saved_event = self.db.get_event_by_id(event['event_id'])
                if saved_event:
                    logger.info(f"âœ“ MySQLéªŒè¯: æ•°æ®å·²æˆåŠŸå­˜å‚¨ (DB ID: {saved_event.id})")
                else:
                    logger.error(f"âœ— MySQLéªŒè¯å¤±è´¥: æ— æ³•æŸ¥è¯¢åˆ°åˆšä¿å­˜çš„æ•°æ®")




            else:
                logger.error(f"âœ—âœ—âœ— ä¿å­˜å¤±è´¥")

            logger.info("=" * 80 + "\n")

            return success

        except Exception as e:
            logger.error(f"âœ—âœ—âœ— å¤„ç†èµ›äº‹å¤±è´¥: {event.get('name')}", exc_info=True)
            logger.error(f"é”™è¯¯è¯¦æƒ…: {e}")
            return False

    def run(self, limit: int = None, max_workers: int = 40):
        """è¿è¡Œçˆ¬è™«ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†èµ›äº‹"""
        logger.info("\n" + "=" * 80)
        logger.info(" " * 30 + "èµ›äº‹çˆ¬è™«å¯åŠ¨")
        logger.info("=" * 80 + "\n")

        success_count = 0
        fail_count = 0
        start_time = time.time()

        try:
            # é˜¶æ®µ1: è·å–èµ›äº‹åˆ—è¡¨
            logger.info("ã€é˜¶æ®µ1ã€‘è·å–èµ›äº‹åˆ—è¡¨")
            logger.info("-" * 80)

            events = self.crawler.crawl_all_events()
            logger.info(f"âœ“ å…±è·å– {len(events)} ä¸ªèµ›äº‹\n")

            if not events:
                logger.error("æ²¡æœ‰è·å–åˆ°ä»»ä½•èµ›äº‹ï¼Œç¨‹åºé€€å‡º")
                return

            # å¦‚æœè®¾ç½®äº†limitï¼Œåªå¤„ç†å‰Nä¸ª
            if limit:
                events = events[:limit]
                logger.info(f"âš  æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {limit} ä¸ªèµ›äº‹\n")

            # é˜¶æ®µ2: å¹¶è¡Œå¤„ç†èµ›äº‹è¯¦æƒ…
            logger.info("ã€é˜¶æ®µ2ã€‘å¹¶è¡Œå¤„ç†èµ›äº‹è¯¦æƒ…")
            logger.info("-" * 80)
            logger.info(f"æ€»è®¡: {len(events)} ä¸ªèµ›äº‹\n")

            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_event = {executor.submit(self.process_event, event): event for event in events}

                for idx, future in enumerate(concurrent.futures.as_completed(future_to_event), 1):
                    event = future_to_event[future]
                    try:
                        success = future.result()
                        if success:
                            success_count += 1
                        else:
                            fail_count += 1
                        logger.info(
                            f"è¿›åº¦: {idx}/{len(events)} | èµ›äº‹: {event['name']} | å¤„ç†ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
                    except Exception as e:
                        fail_count += 1
                        logger.error(f"è¿›åº¦: {idx}/{len(events)} | èµ›äº‹: {event['name']} | å¤„ç†å¼‚å¸¸: {e}")

                    # æ¯10ä¸ªèµ›äº‹æ˜¾ç¤ºä¸€æ¬¡æ•°æ®åº“ç»Ÿè®¡
                    if idx % 10 == 0:
                        stats = self.db.get_stats()
                        logger.info(f"æ•°æ®åº“ç»Ÿè®¡: æ€»è®¡ {stats['total']} æ¡è®°å½•")

            elapsed_time = time.time() - start_time
            stats = self.db.get_stats()

            logger.info("\n" + "=" * 80)
            logger.info(" " * 30 + "çˆ¬è™«è¿è¡Œå®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"å¤„ç†ç»Ÿè®¡:")
            logger.info(f"  - å¤„ç†æ€»æ•°: {len(events)} ä¸ªèµ›äº‹")
            logger.info(f"  - æˆåŠŸ: {success_count} ä¸ª")
            logger.info(f"  - å¤±è´¥: {fail_count} ä¸ª")
            logger.info(
                f"  - æˆåŠŸç‡: {success_count * 100 // (success_count + fail_count) if (success_count + fail_count) > 0 else 0}%")
            logger.info(f"æ•°æ®åº“ç»Ÿè®¡:")
            logger.info(f"  - æ•°æ®åº“è®°å½•æ€»æ•°: {stats['total']}")
            logger.info(f"  - æœ‰èµ„è®¯å†…å®¹: {stats['with_news']}")
            logger.info(f"  - æœ‰è”ç³»æ–¹å¼: {stats['with_contact']}")
            logger.info(f"è€—æ—¶: {elapsed_time:.1f} ç§’ ({elapsed_time / 60:.1f} åˆ†é’Ÿ)")
            logger.info("=" * 80 + "\n")

        except KeyboardInterrupt:
            logger.info("\n\n" + "=" * 80)
            logger.info(" " * 30 + "ç”¨æˆ·ä¸­æ–­çˆ¬è™«")
            logger.info("=" * 80)
            logger.info(f"å·²å¤„ç†: âœ“ æˆåŠŸ {success_count} | âœ— å¤±è´¥ {fail_count}")
            logger.info("=" * 80 + "\n")
        except Exception as e:
            logger.error(f"çˆ¬è™«è¿è¡Œå‡ºé”™: {e}", exc_info=True)

    def process_events_list(self, events):
        """å¤„ç†ç»™å®šçš„èµ›äº‹åˆ—è¡¨ï¼ˆç”¨äºæ—¥æœŸè¿‡æ»¤åçš„å¤„ç†ï¼‰"""
        success_count = 0
        fail_count = 0
        start_time = time.time()

        try:
            logger.info("\n" + "=" * 80)
            logger.info("ã€é˜¶æ®µ2ã€‘å¹¶è¡Œå¤„ç†èµ›äº‹è¯¦æƒ…")
            logger.info("=" * 80)
            logger.info(f"æ€»è®¡: {len(events)} ä¸ªèµ›äº‹\n")

            with concurrent.futures.ThreadPoolExecutor(max_workers=40) as executor:
                future_to_event = {executor.submit(self.process_event, event): event for event in events}

                for idx, future in enumerate(concurrent.futures.as_completed(future_to_event), 1):
                    event = future_to_event[future]
                    try:
                        success = future.result()
                        if success:
                            success_count += 1
                        else:
                            fail_count += 1
                        logger.info(
                            f"è¿›åº¦: {idx}/{len(events)} | èµ›äº‹: {event['name']} | å¤„ç†ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
                    except Exception as e:
                        fail_count += 1
                        logger.error(f"è¿›åº¦: {idx}/{len(events)} | èµ›äº‹: {event['name']} | å¤„ç†å¼‚å¸¸: {e}")

                    # æ¯10ä¸ªèµ›äº‹æ˜¾ç¤ºä¸€æ¬¡æ•°æ®åº“ç»Ÿè®¡
                    if idx % 10 == 0:
                        stats = self.db.get_stats()
                        logger.info(f"æ•°æ®åº“ç»Ÿè®¡: æ€»è®¡ {stats['total']} æ¡è®°å½•")

            elapsed_time = time.time() - start_time
            stats = self.db.get_stats()

            logger.info("\n" + "=" * 80)
            logger.info(" " * 30 + "çˆ¬è™«è¿è¡Œå®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"å¤„ç†ç»Ÿè®¡:")
            logger.info(f"  - å¤„ç†æ€»æ•°: {len(events)} ä¸ªèµ›äº‹")
            logger.info(f"  - æˆåŠŸ: {success_count} ä¸ª")
            logger.info(f"  - å¤±è´¥: {fail_count} ä¸ª")
            logger.info(
                f"  - æˆåŠŸç‡: {success_count * 100 // (success_count + fail_count) if (success_count + fail_count) > 0 else 0}%")
            logger.info(f"æ•°æ®åº“ç»Ÿè®¡:")
            logger.info(f"  - æ•°æ®åº“è®°å½•æ€»æ•°: {stats['total']}")
            logger.info(f"  - æœ‰èµ„è®¯å†…å®¹: {stats['with_news']}")
            logger.info(f"  - æœ‰è”ç³»æ–¹å¼: {stats['with_contact']}")
            logger.info(f"è€—æ—¶: {elapsed_time:.1f} ç§’ ({elapsed_time / 60:.1f} åˆ†é’Ÿ)")
            logger.info("=" * 80 + "\n")

        except KeyboardInterrupt:
            logger.info("\n\n" + "=" * 80)
            logger.info(" " * 30 + "ç”¨æˆ·ä¸­æ–­çˆ¬è™«")
            logger.info("=" * 80)
            logger.info(f"å·²å¤„ç†: âœ“ æˆåŠŸ {success_count} | âœ— å¤±è´¥ {fail_count}")
            logger.info("=" * 80 + "\n")
        except Exception as e:
            logger.error(f"çˆ¬è™«è¿è¡Œå‡ºé”™: {e}", exc_info=True)


def filter_events_by_date(events, start_date=None):
    """
    æŒ‰æ—¥æœŸè¿‡æ»¤èµ›äº‹

    Args:
        events: èµ›äº‹åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ "YYYY-MM-DD"

    Returns:
        è¿‡æ»¤åçš„èµ›äº‹åˆ—è¡¨
    """
    if not start_date:
        return events

    from datetime import datetime
    import re

    try:
        filter_dt = datetime.strptime(start_date, '%Y-%m-%d')
    except Exception as e:
        logger.warning(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {start_date}, {e}")
        return events

    filtered = []
    logger.info(f"\nğŸ“… æ—¶é—´è¿‡æ»¤: >= {start_date}")
    logger.info("-" * 80)

    for event in events:
        basic_info = event.get('basic_info', '')

        # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
        date_patterns = [
            r'(\d{4})\.(\d{1,2})\.(\d{1,2})',  # 2026.12.20
            r'(\d{4})-(\d{1,2})-(\d{1,2})',  # 2026-12-20
            r'(\d{4})/(\d{1,2})/(\d{1,2})',  # 2026/12/20
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥'  # 2026å¹´12æœˆ20æ—¥
        ]

        event_dt = None
        for pattern in date_patterns:
            match = re.search(pattern, basic_info)
            if match:
                try:
                    year, month, day = match.groups()
                    event_dt = datetime(int(year), int(month), int(day))
                    break
                except:
                    continue

        if event_dt and event_dt >= filter_dt:
            filtered.append(event)

    logger.info(f"è¿‡æ»¤ç»“æœ: {len(filtered)}/{len(events)} ä¸ªèµ›äº‹")
    logger.info(f"{'=' * 80}\n")

    return filtered


def main():
    """ä¸»å‡½æ•°ï¼ˆæ”¯æŒå¯¼å…¥/å¯¼å‡º/çˆ¬è™«/æ—¥æœŸè¿‡æ»¤ï¼‰"""
    import argparse

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='èµ›äº‹çˆ¬è™«')

    # å¯é€‰å‚æ•°
    parser.add_argument('--limit', type=int, default=None,
                        help='å¤„ç†èµ›äº‹æ•°é‡é™åˆ¶ï¼ˆæµ‹è¯•ç”¨ï¼‰')
    parser.add_argument('--date', type=str, dest='start_date',
                        help='è¿‡æ»¤æ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD (ä¾‹å¦‚: 2026-12-01)')
    parser.add_argument('--import', dest='import_file', type=str,
                        help='å¯¼å…¥Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--export', dest='export_file', type=str,
                        help='å¯¼å‡ºExcelæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # è®°å½•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ—¥å¿—ä¿¡æ¯
    detail = {'news_url': 'http://example.com/news'}
    logger.info(f"æ„é€ èµ„è®¯é“¾æ¥ï¼ˆæ–¹æ³•2ï¼‰: {detail['news_url']}")

    app = RaceCrawlerApp()
    app.init()

    # ========== æ¨¡å¼1ï¼šå¯¼å…¥ ==========
    if args.import_file:
        logger.info(f"\n{'=' * 80}")
        logger.info(f"ã€å¯¼å…¥æ¨¡å¼ã€‘{args.import_file}")
        logger.info(f"{'=' * 80}\n")

        try:
            from race_events_manager import RaceEventsManager
            manager = RaceEventsManager()
            manager.import_manual_edits(args.import_file)
            logger.info(f"âœ“ å¯¼å…¥å®Œæˆ\n")
        except ImportError:
            logger.error("âŒ æœªæ‰¾åˆ° race_events_manager.py")
            logger.info("æç¤º: è¯·ç¡®ä¿æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
        except Exception as e:
            logger.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")

        # å¦‚æœåªæœ‰å¯¼å…¥ï¼Œæ²¡æœ‰å…¶ä»–æ“ä½œï¼Œç›´æ¥è¿”å›
        if not args.export_file and not args.start_date and not args.limit:
            return

    # ========== æ¨¡å¼2ï¼šçˆ¬è™« ==========
    if args.start_date or args.limit or (not args.import_file and not args.export_file):
        # æ˜¾ç¤ºè¿è¡Œå‚æ•°
        if args.limit:
            logger.info(f"âš™ï¸  è®¾ç½®å¤„ç†é™åˆ¶: {args.limit} ä¸ªèµ›äº‹")

        if args.start_date:
            logger.info(f"âš™ï¸  æ—¥æœŸè¿‡æ»¤: >= {args.start_date}\n")

        # è·å–èµ›äº‹åˆ—è¡¨
        logger.info("\n" + "=" * 80)
        logger.info("ã€é˜¶æ®µ1ã€‘è·å–èµ›äº‹åˆ—è¡¨")
        logger.info("=" * 80)

        events = app.crawler.crawl_all_events()
        logger.info(f"âœ“ å…±è·å– {len(events)} ä¸ªèµ›äº‹\n")

        if not events:
            logger.error("æ²¡æœ‰è·å–åˆ°ä»»ä½•èµ›äº‹ï¼Œç¨‹åºé€€å‡º")
            return

        # æ—¥æœŸè¿‡æ»¤
        if args.start_date:
            events = filter_events_by_date(events, args.start_date)

            if not events:
                logger.error(f"âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„èµ›äº‹ (>= {args.start_date})")
                logger.info("æç¤º: è¯·æ£€æŸ¥æ—¥æœŸæ ¼å¼æˆ–è°ƒæ•´è¿‡æ»¤æ¡ä»¶")
                return

        # limitè¿‡æ»¤
        if args.limit:
            events = events[:args.limit]
            logger.info(f"âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {args.limit} ä¸ªèµ›äº‹\n")

        # å¤„ç†èµ›äº‹
        app.process_events_list(events)

    # ========== æ¨¡å¼3ï¼šå¯¼å‡º ==========
    if args.export_file:
        logger.info(f"\n{'=' * 80}")
        logger.info(f"ã€å¯¼å‡ºæ¨¡å¼ã€‘{args.export_file}")
        logger.info(f"{'=' * 80}\n")

        try:
            from race_events_manager import RaceEventsManager
            manager = RaceEventsManager()
            manager.export_to_excel(args.export_file)
            logger.info(f"âœ“ å¯¼å‡ºå®Œæˆ\n")
        except ImportError:
            logger.error("âŒ æœªæ‰¾åˆ° race_events_manager.py")
            logger.info("æç¤º: è¯·ç¡®ä¿æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")


if __name__ == '__main__':
    main()